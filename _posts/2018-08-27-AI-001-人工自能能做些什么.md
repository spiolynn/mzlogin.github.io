---
layout:     post
title:      AI-001-人工自能能做些什么
subtitle:    "\"Hello World\""
date:       2018-08-26
author:     PZ
header-img: img/post-bg-2015.jpg
catalog: true
tags:
    - AI
    - DL
---

# 深度学习-IS


## 0 开个头

> 人工智能，深度学习，机器学习……不管你在从事什么工作，都需要了解这些概念。否则的话，三年之内你就会变成一只恐龙。 —— 马克·库班





## 1 AI ML DL 从头说起


![image](https://blogs.nvidia.com/wp-content/uploads/2016/07/Deep_Learning_Icons_R5_PNG.jpg.png)

-  1956 年计算机科学家们在达特茅斯会议，心中的梦想是希望通过当时新兴的计算机，打造拥 有相当于人类智能的复杂机器，这就是我们所说的“==通用人工智能==”（General             AI）概念，拥有人类五感（甚至更多）、推理能力以及人类思维方式的神奇机器。
==感知== ==归纳== ==推理== ， 但是结果是事与愿违的，多年过去了，General AI 可能还只是存在于小说和电影里。


- 退而求其次，大神们想着去执行特定任务，同时希望机器的水平与人类相当，甚至超越人类
这就是==弱人工智能==”（Narrow AI）的概念 。而 ==机器学习：实现人工智能的一种方法==（准确来说是Narrow AI） （目前来看是最主要的方法）

- 而深度学习又是基于神经网络(NN)算法，完成机器学习，目前看来最高效的一种方法。

### 1.1 实现人工智能的一些方法

#### 1.1.1 问题求解
```
问题求解，即解决管理活动中由于意外引起的非预期效应
或与预期效应之间的偏差。能够求解难题的下棋(如国际象棋) 程序的出现，是人工智能发展的一大成就

（逐渐发展成为搜索和问题归约这类人工智能的基本技术）
（搜索策略可分为无信息导引的盲目搜索和利用经验知识导引的启发式搜索）

机器下棋的算法本质都是搜索树，围棋难在它的树宽可以达到好几百（国际象棋只有几十）。在有限时间内要遍历这么宽的树，就只能牺牲深度（俗称“往后看几步”），但围棋又是依赖远见的游戏，甚至不仅是看“几步”的问题。所以，要想保证搜索深度，就只能放弃遍历，改为随机采样——这就是为什么在没有MCTS（蒙特卡罗搜树）类的方法之前，机器围棋的水平几乎是笑话。而采用了MCTS方法后，搜索深度就大大增加了
```

#### 1.1.2 专家系统ES（Expert System）

```
专家系统可看作一类具有专门知识的计算机智能程序系统，（咨询对话）

它求解方法是一种启发式方法，专家系统所要解决的问题一般无算法解，并且与传统的计算机程序上不同之处在于'它要经常在不完全、不精确或不确定的信息基础上做出结论。

（客服机器人、医疗诊断）

发展专家系统的关键在于表达和运用专家知识。

知识库、数据库、推理机、解释机制、知识获取和用户界面六部分组成
```

```
graph LR
用户界面-->推理机
用户界面-->解释机
用户界面-->知识获取
推理机-->知识库&数据库
解释机-->知识库&数据库
知识获取-->知识库&数据库
```

#### 1.1.2 机器学习

--- 
> ==机器学习是用数据或以往的经验，以此优化计算机程序的性能标准,到达完成人类对某个事物的认知、分类、判断、决策、预测的能力==

    看出 机器学习中 数据、算法是两个关键的东西，数据能使算法的"智慧性"提高，便是机器学习的核心。

> 问题: 机器学习 是如何通过数据、算法来解决对某个事物的认知、分类、判断、决策、预测的能力呢？

    机器学习已经有了十分广泛的应用，例如：数据挖掘、计算机视觉、自然语言处理、生物
    特征识别、搜索引擎、医学诊断、检测信用卡欺诈、证券市场分析、DNA序列测序、语音
    和手写识别、战略游戏和机器人运用。


### 1.2 深度学习目前的应用

话分两头，既然知道了人工智能、机器学习、深度学习的关系（现在大家在说AI或者机器学习时可能80%提的都是基于DeepLearning了一个应用），在了解深度学习的细节之前，我们可以看看，目前DL在业界以及实现或正在尝试的应用。

::: info
> 引用

> https://www.zhihu.com/question/47563637

> https://www.zhihu.com/question/39506931

:::

#### 1.2.1 如你所想常见的应用

AWS 提供计算机视觉云服务

![image](https://d1.awsstatic.com/product-marketing/Rekognition/Label-detection.b3858b2903ec631bef4603b6689848ed342a4400.png)

object 识别

您可以识别数千种对象 (例如自行车、电话、建筑) 和场景 (例如停车场、海滩、城市)。在分析视频时，您还可以识别帧中发生的具体活动，例如“交付包裹”或“踢足球”


![image](https://d1.awsstatic.com/FACE-DETECTION.3f01d860b752d3077dbfedd27b3c76bc25d79f1a.png)
人脸相关识别

您可以分析图像和视频中面孔的属性，以确定开心程度、年龄范围、眼睛睁开程度、眼镜、面部毛发等。在视频中，您也可以衡量这些方面随时间的变化，比如构建一个演员情感的时间线。


![image](https://d1.awsstatic.com/DRUGSTORE.d9b1db8122d2301d6a29f89373c4a8557a3180d6.png)
视频跟踪

使用 Rekognition 分析视频时，即使他们的面孔不可见，或者在他们进出场景时，也可以通过视频跟踪人员。您还可以在帧中识别他们的动作，以告知一些信息，比如某人是否正在进入或离开建筑。

![image](https://d1.awsstatic.com/FPO%20Images/text_in_image_on_website_napkin_words.c95f79e666b67737b3e5ec1eaa1c451a6210aa3f.png)
场景下文本识别

Rekognition 专门用于处理现实世界的图像，可以检测和识别图像中的文字，如街道名称、字幕、产品名称和车牌。

#### 1.2.2 AI 主播


在Twitch上玩侠盗列车手的主播“查尔斯”

```
python 写的基于NN的人工智能程序
它的一切操作都要基于捕捉到的每一帧画面来实时分析，并在无尽的试错中总结出来能让自己顺利前进的规则
```

![image](https://pic1.zhimg.com/80/v2-7aa883452c289392fd5ff2ac0b7bcd4e_hd.jpg)


- 围观查尔斯在Twitch上开车
> https://www.twitch.tv/sentdex


#### 1.2.2 AI写唐诗宋词 写小说

> http://couplet.msra.cn/jueju/

> http://poem.bosonnlp.com/?utm_source=next.36kr.com

来一首（使用微软的自动写诗系统）
```
风光正春日，一蝶雨中飞。粉翅来何许，临水惜芳菲
```

来一首（使用编诗姬完成）

![image.png](http://upload-images.jianshu.io/upload_images/10357485-a2a242b210347b93.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240)


Chinese Poetry Generation with Recurrent Neural Networks 

A recurrent neural network for generating little stories about images

#### 1.2.3 Deep Dream/风格模仿

> https://deepdreamgenerator.com/

> http://www.ltaaa.com/bbs/thread-364424-1-1.html

Deep Dream 是 google 为了实现深度学习可视化的产出物（就是还开了画展、还卖了钱10W、很神奇），所谓深度学习可视化，其实是试图展示在DL中神经网络不同层次间反应的是对象的何种特征，

比如在low-level层展示了是事物的边缘特征，展示出来的图可能是这样的
![image](http://img.ltaaa.com/bbs/forum/201508/21/124551to9v7rh0at5eere5.jpg.thumb.jpg)

比如在high-level层展示了是事物的形状特征，展示出来的图可能是这样的
![image](https://ddg-mjesip8vchewh1dsl.stackpathdns.com/assets/landing/img/gallery/4.jpg)

下面两幅则是style learning

![image](https://raw.githubusercontent.com/fzliu/style-transfer/master/images/content/johannesburg.jpg)

![image](https://raw.githubusercontent.com/fzliu/style-transfer/master/images/results/starry_johannesburg.jpg)

> https://github.com/fzliu/style-transfer


#### 1.2.4 图片修复

> https://link.zhihu.com/?target=http%3A//www.cv-foundation.org/openaccess/content_cvpr_2016/papers/Pathak_Context_Encoders_Feature_CVPR_2016_paper.pdf

![image](https://pic4.zhimg.com/80/a56a811e1a5c1108d2393cf84da6821d_hd.jpg)

#### 1.2.5 创作风格音乐/yi

> http://www.cnblogs.com/charlotte77/p/5664523.html

> https://github.com/DmitryUlyanov/neural-style-audio-tf


#### 1.2.6 表情移植

斯坦福

![image](https://pic3.zhimg.com/80/v2-b23dff60c04bb1810015746914293428_hd.jpg)


#### 1.2.7 图片AI上色

> http://demos.algorithmia.com/colorize-photos/

![image](https://pic1.zhimg.com/80/v2-92da50cb487ec6a22adf401451974ae1_hd.jpg)

例子: http://t2.hddhhn.com/uploads/tu/20150420/12990-ALoYuZ.jpg


### 1.3 深度学习知识图谱

我们上面看到的例子，无一例外使用的都是深度学习方法，实现机器学习的应用。更具体一点使用的是CNN 和 RNN 两种常见的深度学习模型完成。

> 问题 ：那么问题来了，深度学习是个什么东西呢？

问题先放一放，先丢一张所谓知识图谱，让我们有一个总体的了解：

    数据、算法、模型 组成了一个深度学习应用的核心
    
    常用工具和框架则是实现应用的高效武器

![知识图谱](https://pic1.zhimg.com/50/v2-bc6c0d1aecc63ed1b20baaa4fc71dd35_hd.jpg)

![知识图谱](https://pic3.zhimg.com/v2-791751c855d27cf94d88654b175e0470_r.jpg)



## 2 深度学习的前世今生

铺垫了那么多，终于要进入到我们的主题，什么是深度学习，可是还是要等一等，在这之前，我们还要说一说机器学习。

### 2.1 机器学习传统方法

我们都知道在深度学习火起来之前，其实机器学习已经在业内讨论的风声水起，相关的算法、论文层出不穷，在图像识别、语音识别、自然语言理解、基因表达、内容推荐等应用上均取得的不错的进展。

我们以笔者比较了解的图像识别（模式识别）为例，介绍一下实现的基本套路


![image](http://img.my.csdn.net/uploads/201304/08/1365435432_2281.jpg)


:::info
图像识别中，经典的套路如下：

1 开始的通过传感器（例如CMOS）来获得数据

2 经过预处理、特征提取、特征选择 （特征表达）得到表达图像信息的数学特征

3 利用特征、通过算法实现识别

预处理、特征提取、特征选择 我们可以统一称为==特征表达==

而前期的机器学习，我们最常做的事情就是，**找好的特征，找好的机器学习算法**

:::

![image](http://img.my.csdn.net/uploads/201304/08/1365435468_8350.jpg)


#### 2.1.1 举一个栗子

- 识别图像中的文字区域，传统的方法是，我们需要找一找文字和非文字的区别，并且使用将区别使用数学方式表达出来：

![image.png](http://upload-images.jianshu.io/upload_images/10357485-20f0e003ae99a3f4.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240)


- 嗯 我们来列出一些


![image.png](http://upload-images.jianshu.io/upload_images/10357485-10d5b0e391272d3c.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240)


    几何特征：
    
    a)	区域面积 Area(r)=sum((i,j)⊆r)
    b)	区域宽高比 Ratio_WH（r） =Width（r）/Height（r）    
    c)	占有比Ratio_Area（r） =Area（r）/(Width（r）×Height（r） )        
    
    形状特征：
    
    a)	紧密度 Compactness（r）= Perimeter（r）^2/Area（r）
    b)	欧拉数（孔洞数）
    c)	粗糙度 Roughness（r）=〖Perimeter（r）〗^open（Strel） /Perimeter（r）
    
    颜色特征：
    
    a)  颜色方差
    
    笔画特征：
    a)	笔画宽度均值和笔画宽度方差 StrokeWidthMean（r）=(∑_(i∈r)▒StrokeWidth（i） )/Area（r） 
    b)	笔画宽度方差均值比 StrokeWidthMeanDeviation（r）=StrokeWidthDeviation（r）/StrokeWidthMean（r）   
    a)	笔画长度 StrokeLength（r）=Area（r）/StrokeWidthMean（r）

![image.png](http://upload-images.jianshu.io/upload_images/10357485-7642e1561c7e9d19.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240)


- 有了这么多的特征，需要分析特征的区分性

![image.png](http://upload-images.jianshu.io/upload_images/10357485-3a4e5c71ee880f0e.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240)

可以发现具有最好区分度的分类特征描述为笔画长度，最差的为孔洞数。

- 好了我知道哪些特征是`好`特征、哪些是`不好`的，现在需要建造一个分类算法。

> http://blog.csdn.net/u014088052/article/details/50834033

```
贝叶斯
KNN算法
SVM
Boosting(级联分类器)
神经网络
```
- 我们使用一个弱级联分类器算法试试

![image.png](http://upload-images.jianshu.io/upload_images/10357485-61aa372b32a5a051.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240)

- 来看看结果，看起来还不错

![image.png](http://upload-images.jianshu.io/upload_images/10357485-81ed4fe8345fc229.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240)


- 但是如果图片场景更加复杂一些，情况就不是那么乐观了

![image.png](http://upload-images.jianshu.io/upload_images/10357485-01ed81171dc19295.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240)


#### 2.1.2 传统机器学习获取一个好特征很重要

传统机器学习获取一个好特征很重要，一个好的特征应具有不变性（大小、尺度和旋转、光源等）和可区分性

如下是前人总结的"好"特征

![image](http://img.my.csdn.net/uploads/201304/08/1365435491_6508.jpg)


但是: IT人最大的优点是懒惰，他们想:

手工地选取特征是一件非常费力、启发式（需要专业知识）的方法，能不能选取好很大程度上靠经验和运气，而且它的调节需要大量的时间，==既然手工选取特征不太好，那么能不能自动地学习一些特征呢==

嗯 不错的想法，由此深度学习有了一个重要的特性，`不可解释`，因为开发他的人也不知道他是怎么"想"的


### 2.2 深度学习


#### 2.2.1 简单的历史

1 深度学习框架，基于人工神经网络，1980 福岛邦彦提出的**新认知机**

2 1989年，扬·勒丘恩（Yann LeCun）等人开始将1974年提出的标准**反向传播算法**（BP）应用于深度神经网络，计算量巨大

3 由于尔根·施密德胡伯的学生赛普·霍克赖特于1991年提出的梯度消减

4 2006年，加拿大多伦多大学教授、机器学习领域的泰斗Geoffrey Hinton和他的学生RuslanSalakhutdinov在《科学》上发表了一篇文章，开启了深度学习在学术界和工业界的浪潮。这篇文章有两个主要观点：1）多隐层的人工神经网络具有优异的特征学习能力，学习得到的特征对数据有更本质的刻画，从而有利于可视化或分类；2）深度神经网络在训练上的难度，可以通过“逐层初始化”（layer-wise pre-training）来有效克服，在这篇文章中，逐层初始化是通过无监督学习实现的。

5 2012年，《纽约时报》披露了Google Brain项目，这个项目是由著名的斯坦福大学的机器学习教授Andrew Ng和在大规模计算机系统方面的世界顶尖专家JeffDean共同主导，用16000个CPU Core的并行计算平台训练一种称为“深度神经网络”（DNN，Deep Neural Networks）的机器学习模型（内部共有10亿个节点。),在语音识别和图像识别等领域获得了巨大的成功

6 2012年11月,微软在中国天津的一次活动上公开演示了一个全自动的同声传译系统,后面支撑的关键技术也是DNN，或者深度学习（DL，DeepLearning）

7  2013年1月,在百度年会上，创始人兼CEO李彦宏高调宣布要成立百度研究院，其中第一个成立的就是“深度学习研究所”（IDL，Institue of Deep Learning）

8  2016年开始 哪里都是人工智能

![image.png](http://upload-images.jianshu.io/upload_images/10357485-fcfa2941728256c3.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240)


#### 2.2.2 神经网络

#### 2.2.2.1 人脑的视觉机理

1981 年的诺贝尔医学奖，颁发给了 David Hubel（出生于加拿大的美国神经生物学家） 和TorstenWiesel，以及 Roger Sperry。前两位的主要贡献，是“发现了视觉系统的信息处理”：可视皮层是分级的：

David Hubel 和Torsten Wiesel 发现了一种被称为“方向选择性细胞（Orientation Selective Cell）”的神经元细胞。当瞳孔发现了眼前的物体的边缘，而且这个边缘指向某个方向时，这种神经元细胞就会活跃。

这个发现激发了人们对于神经系统的进一步思考。神经-中枢-大脑的工作过程，或许是一个不断迭代、不断抽象的过程。

![image](http://img.my.csdn.net/uploads/201304/08/1365435554_6921.jpg)

人的视觉系统的信息处理是分级的。从低级的V1区提取边缘特征，再到V2区的形状或者目标的部分等，再到更高层，整个目标、目标的行为等。也就是说高层的特征是低层特征的组合，从低层到高层的特征表示越来越抽象，越来越能表现语义或者意图。而抽象层面越高，存在的可能猜测就越少，就越利于分类。

例如，从原始信号摄入开始（瞳孔摄入像素 Pixels），接着做初步处理（大脑皮层某些细胞发现边缘和方向），然后抽象（大脑判定，眼前的物体的形状，是圆形的），然后进一步抽象（大脑进一步判定该物体是只气球）。

> 敏感的人注意到关键词了：分层。而Deep learning的deep是不是就表示我存在多少层，也就是多深呢？没错。那Deep learning是如何借鉴这个过程的呢？毕竟是归于计算机来处理，面对的一个问题就是怎么对这个过程建模？

#### 2.2.2.2 特征的粒度

特征是机器学习系统的原材料，如果数据被很好的表达成了特征，后续就好办了

> 学习算法在一个什么粒度上的特征表示，才有能发挥作用？

就一个图片来说，像素级的特征根本没有价值。例如下面的摩托车，从像素级别，根本得不到任何信息，其无法进行摩托车和非摩托车的区分。而如果特征是一个具有==结构性==（或者说有含义）的时候，比如是否具有车把手（handle），是否具有车轮（wheel），就很容易把摩托车和非摩托车区分，学习算法才能发挥作用。
![image](http://img.my.csdn.net/uploads/201304/09/1365438575_9396.jpg)
![image](http://img.my.csdn.net/uploads/201304/09/1365438590_4831.jpg)


#### 2.2.2.3 图像世界的基 - 初级（浅层）特征表示

1995 年前后，Bruno Olshausen和 David Field，完成了一个实验，实验过程省略，结论是：
复杂图形，往往由一些基本结构组成，比如下图：一个图可以通过用64种正交的edges（可以理解成正交的基本结构）来线性表示。比如样例的x可以用1-64个edges中的三个按照0.8,0.3,0.5的权重调和而成。而其他基本edge没有贡献，因此均为0 。

![image](http://img.my.csdn.net/uploads/201304/09/1365438649_2577.jpg)

厉害了： 这个实验告诉我们，如果我们的64种正交edges是8*8像素的图像，那么对于一张64*64的图片我们可以用8*8的64维向量表示，听起来好像并没有什么差别，都是64*64的数字表示，但是它做了一次64维的空间变换，这在分类上，其实就是多了一种可能性。

类似的情况，也发生在声音上：（从未标注的声音中发现了20种基本的声音结构，其余的声音可以由这20种基本结构合成）

![image](http://img.my.csdn.net/uploads/201304/09/1365438664_7093.jpg)

![image](http://img.my.csdn.net/uploads/201304/09/1365438678_4293.jpg)


#### 2.2.2.4 结构性特征表示

![image](http://img.my.csdn.net/uploads/201304/09/1365438722_9668.jpg)

V1取提出的basis是边缘，然后V2层是V1层这些basis的组合，这时候V2区得到的又是高一层的basis。即上一层的basis组合的结果，上上层又是上一层的组合basis……（所以有大牛说Deep learning就是“搞基”，因为难听，所以美其名曰Deep learning或者Unsupervised Feature Learning）

![image](http://img.my.csdn.net/uploads/201304/09/1365438750_9009.jpg)

在不同object上做training是，所得的edge basis 是非常相似的，但object parts和models 就会completely different了（那咱们分辨car或者face是不是容易多了）：


![image](http://img.my.csdn.net/uploads/201304/09/1365439360_3108.jpg)

##### 2.2.2.5 什么是深度学习

深度学习的实质，是通过构建具有很多隐层的机器学习模型和海量的训练数据，来学习更有用的特征，从而最终提升分类或预测的准确性。因此，“深度模型”是手段，“特征学习”是目的。区别于传统的浅层学习，深度学习的不同在于：1）强调了模型结构的深度，通常有5层、6层，甚至10多层的隐层节点；2）明确突出了特征学习的重要性，也就是说，通过逐层特征变换，将样本在原空间的特征表示变换到一个新特征空间，从而使分类或预测更加容易。与人工规则构造特征的方法相比，利用大数据来学习特征，更能够刻画数据的丰富内在信息。==

