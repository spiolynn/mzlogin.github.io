---
layout:     post
title:      002-Keras-学习笔记之顺序模型
subtitle:    "\"Keras-学习笔记之顺序模型\""
date:       2018-08-28
author:     PZ
header-img: img/post-bg-2015.jpg
catalog: true
tags:
    - keras
    - AI
    - DL
---

```
2018-08-28-002-Keras-学习笔记之顺序模型.md
```

[TOC]

## 002-Keras-学习笔记之顺序模型

### 1 keras两种模型层次构建方法

#### 1.1 Sequential-顺序模型

- 在DL的模型设计环节 一共会有三个部分
    - 模型设计 (model 的层次结构)
    - 模型编译 (model 的loss(损失函数) optimizer(优化器) metrics(评估标准))
    - 模型训练 (model data label epochs(训练轮数) batch_size)

```
## step1 : 建模
model = Sequential()
# input_shape = 模型输入尺寸的元组(784维向量)
# 如果你同时将 batch_size=32 和 input_shape=(6, 8) 传递给一个层，那么每一批输入的尺寸就为 (32，6，8)
model.add(Dense(32, input_shape=(784,)))
model.add(Activation('relu'))
model.add(Dense(10))
model.add('softmax')

## step2 : compile 编译
## 编译小三人：optimizer，loss，metrics

#==================
# 多分类问题
model.compile(optimizer='rmsprop',
              loss='categorical_crossentropy',
              metrics=['accuracy'])

# 二分类问题
model.compile(optimizer='rmsprop',
              loss='binary_crossentropy',
              metrics=['accuracy'])

# 均方误差回归问题
model.compile(optimizer='rmsprop',
              loss='mse')

# 自定义评估标准函数
import keras.backend as K

def mean_pred(y_true, y_pred):
    return K.mean(y_pred)

model.compile(optimizer='rmsprop',
              loss='binary_crossentropy',
              metrics=['accuracy', mean_pred])
# ===============================================

## step3 fit 训练
import numpy as np
data = np.random.random((1000, 100))
labels = np.random.randint(2, size=(1000, 1))
# 训练模型，以 32 个样本为一个 batch 进行迭代
model.fit(data, labels, epochs=10, batch_size=32)
```

#### 1.2 这是一个简单的小例子

- 如下是一个最简单的模型训练的例子

> **模型** : 32个节点的全连接 加 10个节点的 softmax <br>
> optimizer=rmsprop  loss=categorical_crossentropy  metrics=accuracy <br>
> epochs=10, batch_size=32


```
from __future__ import print_function
import keras
from keras.datasets import mnist
from keras.models import Sequential
from keras.layers import Dense, Dropout, Flatten,Activation
from keras.layers import Conv2D, MaxPooling2D
from keras import backend as K
import numpy as np

# 对于具有10个类的单输入模型（多分类分类）：

model = Sequential()
model.add(Dense(32, activation='relu', input_shape=(100,)))
model.add(Dense(10, activation='softmax'))
model.compile(optimizer='rmsprop',
              loss='categorical_crossentropy',
              metrics=['accuracy'])

# 生成虚拟数据
import numpy as np
data = np.random.random((1000, 100))
## 生成0-9 随机数 (1000,1) 1000维列向量
labels = np.random.randint(10, size=(1000, 1))

# 将标签转换为分类的 one-hot 编码
one_hot_labels = keras.utils.to_categorical(labels, num_classes=10)

# 训练模型，以 32 个样本为一个 batch 进行迭代
model.fit(data, one_hot_labels, epochs=10, batch_size=32)
```


> 结果

```
Epoch 1/10
2018-08-28 16:01:30.683206: I tensorflow/core/platform/cpu_feature_guard.cc:141] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX

  32/1000 [..............................] - ETA: 10s - loss: 2.3341 - acc: 0.1250
 928/1000 [==========================>...] - ETA: 0s - loss: 2.3430 - acc: 0.1013 
1000/1000 [==============================] - 0s 410us/step - loss: 2.3414 - acc: 0.0990
Epoch 2/10

  32/1000 [..............................] - ETA: 0s - loss: 2.2421 - acc: 0.1250
 928/1000 [==========================>...] - ETA: 0s - loss: 2.3071 - acc: 0.1121
1000/1000 [==============================] - 0s 59us/step - loss: 2.3051 - acc: 0.1100
Epoch 3/10

  32/1000 [..............................] - ETA: 0s - loss: 2.2262 - acc: 0.1562
 928/1000 [==========================>...] - ETA: 0s - loss: 2.2935 - acc: 0.1121
1000/1000 [==============================] - 0s 59us/step - loss: 2.2911 - acc: 0.1170
Epoch 4/10

  32/1000 [..............................] - ETA: 0s - loss: 2.2493 - acc: 0.1875
 832/1000 [=======================>......] - ETA: 0s - loss: 2.2814 - acc: 0.1178
1000/1000 [==============================] - 0s 66us/step - loss: 2.2833 - acc: 0.1220
Epoch 5/10

  32/1000 [..............................] - ETA: 0s - loss: 2.2442 - acc: 0.2500
 800/1000 [=======================>......] - ETA: 0s - loss: 2.2736 - acc: 0.1313
1000/1000 [==============================] - 0s 69us/step - loss: 2.2767 - acc: 0.1350
Epoch 6/10

  32/1000 [..............................] - ETA: 0s - loss: 2.1889 - acc: 0.2500
 928/1000 [==========================>...] - ETA: 0s - loss: 2.2678 - acc: 0.1562
1000/1000 [==============================] - 0s 58us/step - loss: 2.2699 - acc: 0.1550
Epoch 7/10

  32/1000 [..............................] - ETA: 0s - loss: 2.2791 - acc: 0.1250
 928/1000 [==========================>...] - ETA: 0s - loss: 2.2611 - acc: 0.1401
1000/1000 [==============================] - 0s 58us/step - loss: 2.2612 - acc: 0.1430
Epoch 8/10

  32/1000 [..............................] - ETA: 0s - loss: 2.2477 - acc: 0.1875
 864/1000 [========================>.....] - ETA: 0s - loss: 2.2563 - acc: 0.1551
1000/1000 [==============================] - 0s 65us/step - loss: 2.2533 - acc: 0.1520
Epoch 9/10

  32/1000 [..............................] - ETA: 0s - loss: 2.2979 - acc: 0.1250
 800/1000 [=======================>......] - ETA: 0s - loss: 2.2483 - acc: 0.1512
1000/1000 [==============================] - 0s 66us/step - loss: 2.2471 - acc: 0.1530
Epoch 10/10

  32/1000 [..............................] - ETA: 0s - loss: 2.1682 - acc: 0.3125
 928/1000 [==========================>...] - ETA: 0s - loss: 2.2358 - acc: 0.1638
1000/1000 [==============================] - 0s 58us/step - loss: 2.2384 - acc: 0.1600

Process finished with exit code 0
```

#### 1.3 更多没有数据的模型例子

> https://keras.io/zh/getting-started/sequential-model-guide/#keras-sequential <br> 更多例子 可以参考这里

- 图像常用的VGG模型

```
import numpy as np
import keras
from keras.models import Sequential
from keras.layers import Dense, Dropout, Flatten
from keras.layers import Conv2D, MaxPooling2D
from keras.optimizers import SGD

# 生成虚拟数据
x_train = np.random.random((100, 100, 100, 3))
y_train = keras.utils.to_categorical(np.random.randint(10, size=(100, 1)), num_classes=10)
x_test = np.random.random((20, 100, 100, 3))
y_test = keras.utils.to_categorical(np.random.randint(10, size=(20, 1)), num_classes=10)

model = Sequential()
# 输入: 3 通道 100x100 像素图像 -> (100, 100, 3) 张量。
# 使用 32 个大小为 3x3 的卷积滤波器。
model.add(Conv2D(32, (3, 3), activation='relu', input_shape=(100, 100, 3)))
model.add(Conv2D(32, (3, 3), activation='relu'))
model.add(MaxPooling2D(pool_size=(2, 2)))
model.add(Dropout(0.25))

model.add(Conv2D(64, (3, 3), activation='relu'))
model.add(Conv2D(64, (3, 3), activation='relu'))
model.add(MaxPooling2D(pool_size=(2, 2)))
model.add(Dropout(0.25))

model.add(Flatten())
model.add(Dense(256, activation='relu'))
model.add(Dropout(0.5))
model.add(Dense(10, activation='softmax'))

sgd = SGD(lr=0.01, decay=1e-6, momentum=0.9, nesterov=True)
model.compile(loss='categorical_crossentropy', optimizer=sgd)

model.fit(x_train, y_train, batch_size=32, epochs=10)
score = model.evaluate(x_test, y_test, batch_size=32)

print('test data score: \n')
print(score)
```


- 栈式 LSTM

```
from keras.models import Sequential
from keras.layers import LSTM, Dense
import numpy as np

data_dim = 16
timesteps = 8
num_classes = 10

# 期望输入数据尺寸: (batch_size, timesteps, data_dim)
model = Sequential()
model.add(LSTM(32, return_sequences=True,
               input_shape=(timesteps, data_dim)))  # 返回维度为 32 的向量序列
model.add(LSTM(32, return_sequences=True))  # 返回维度为 32 的向量序列
model.add(LSTM(32))  # 返回维度为 32 的单个向量
model.add(Dense(10, activation='softmax'))

model.compile(loss='categorical_crossentropy',
              optimizer='rmsprop',
              metrics=['accuracy'])

# 生成虚拟训练数据
x_train = np.random.random((1000, timesteps, data_dim))
y_train = np.random.random((1000, num_classes))

# 生成虚拟验证数据
x_val = np.random.random((100, timesteps, data_dim))
y_val = np.random.random((100, num_classes))

model.fit(x_train, y_train,
          batch_size=64, epochs=5,
          validation_data=(x_val, y_val))
```

#### 1.4 问题

> 1 模型的结构是什么样子的? - 需要可视化

> 2 模型训练、验证、测试数据 已经评估分数的含义? - 深入了解 loss optimizer metrics scores

> 3 对于大量真实数据，效率问题?  - GPU? 内存影响? 分批导入

> 4 VGG? LSTM?  - 需要更深入了解模型的原理


