---
layout:     post
title:      002-机器学习简介-TensorFlow
subtitle:    "\"002-机器学习简介-TensorFlow\""
date:       2018-09-25
author:     PZ
header-img: img/post-bg-2015.jpg
catalog: true
tags:
    - ML
    - 理论
    - TensorFlow
---


# 机器学习简介

[TOC]

---
## 引用
> https://developers.google.com/machine-learning/crash-course/ml-intro

==scikit-learn== 是极其热门的 Python 开放源代码机器学习库
 
> http://scikit-learn.org/stable/index.html

可使用 ==Colaboratory== 平台直接在浏览器中运行编程练习（无需设置！）

> https://colab.research.google.com/notebooks/welcome.ipynb#recent=true


---

> 第一集 https://www.bilibili.com/video/av20263128?from=search&seid=6383524691819346919


---


## 1 问题构建 (Framing)：机器学习主要术语

### 1 什么是（监督式）机器学习？简单来说，它的定义如下：

- 机器学习系统通过学习如何组合输入信息来对从未见过的数据做出有用的预测。


### 1 标签

    在简单线性回归中，标签是我们要预测的事物，即 y 变量。标签可以是小麦未来的价格、图片中显示的动物品种、音频剪辑的含义或任何事物。

### 2 特征

    在简单线性回归中，特征是输入变量，即 x 变量。简单的机器学习项目可能会使用单个特征，而比较复杂的机器学习项目可能会使用数百万个特征，按如下方式指定：
    
        {X1,X2,...,XN}
    
    在垃圾邮件检测器示例中，特征可能包括：
    ```
    电子邮件文本中的字词
    发件人的地址
    发送电子邮件的时段
    电子邮件中包含“一种奇怪的把戏”这样的短语。
    ```

###  3 样本

样本是指数据的特定实例：x。（我们采用粗体表示它是一个矢量。）我们将样本分为以下两类：

    有标签样本
    无标签样本

有标签样本同时包含特征和标签。即：

    labeled examples: {features, label}: (x, y)

我们使用有标签样本来训练模型。在我们的垃圾邮件检测器示例中，有标签样本是用户明确标记为“垃圾邮件”或“非垃圾邮件”的各个电子邮件。


###  4 模型

模型定义了特征与标签之间的关系。例如，垃圾邮件检测模型可能会将某些特征与“垃圾邮件”紧密联系起来。我们来重点介绍一下模型生命周期的两个阶段：

- **训练**表示创建或学习模型。也就是说，您向模型展示有标签样本，让模型逐渐学习特征与标签之间的关系。

- **推断**表示将训练后的模型应用于无标签样本。也就是说，您使用训练后的模型来做出有用的预测 (y')。例如，在推断期间，您可以针对新的无标签样本预测 medianHouseValue。


### 5 回归与分类

- **回归模型**可==预测连续值==。例如，回归模型做出的预测可回答如下问题：
    ```
    加利福尼亚州一栋房产的价值是多少？
    用户点击此广告的概率是多少？
    ```
- **分类模型**可==预测离散值==。例如，分类模型做出的预测可回答如下问题：
    ```
    某个指定电子邮件是垃圾邮件还是非垃圾邮件？
    这是一张狗、猫还是仓鼠图片？
    ```
    
## 2 深入了解机器学习

### 2.1 基础回归模型--线性回归


人们早就知晓，相比凉爽的天气，蟋蟀在较为炎热的天气里鸣叫更为频繁。数十年来，专业和业余昆虫学者已将每分钟的鸣叫声和温度方面的数据编入目录。

![image.png](http://upload-images.jianshu.io/upload_images/10357485-7a0d6d3afb778572.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240)

<center>图 1. 每分钟的鸣叫声与温度（摄氏度）的关系。</center>

---

毫无疑问，此曲线图表明温度随着鸣叫声次数的增加而上升。鸣叫声与温度之间的关系是线性关系吗？是的，您可以绘制一条直线来近似地表示这种关系，如下所示：

![image.png](http://upload-images.jianshu.io/upload_images/10357485-25ddb32a1f4c7078.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240)

<center>图 2. 线性关系。</center>

事实上，虽然该直线并未精确无误地经过每个点，但针对我们拥有的数据，清楚地显示了鸣叫声与温度之间的关系。只需运用一点代数知识，您就可以将这种关系写下来，如下所示：

`$y = mx+b$` 

其中：

`$y$` 指的是温度（以摄氏度表示），即我们试图预测的值。

`$m$` 指的是直线的斜率。

`$x$` 指的是每分钟的鸣叫声次数，即输入特征的值。

`$b$` 指的是 y 轴截距。

按照机器学习的惯例，您需要写一个存在细微差别的模型方程式：

:::info
`$y' = w_1x_1+b$`
:::

其中：

:::info

`$y'$` 指的是预测标签（理想输出值）。
 
`$b$` 指的是偏差（y 轴截距）。而在一些机器学习文档中，它称为 `$w_0$`。
 
`$w_1$` 指的是特征 1 的权重。权重与上文中用  表示的“斜率”的概念相同。
 
`$x_1$` 指的是特征（已知输入项）。
:::

要根据新的每分钟的鸣叫声值`$x_1$`  **推断**（预测）温度`$y'$` ，只需将 `$x_1$` 值代入此模型即可。

下标（例如 `$w_1$` 和 `$x_1$`）预示着可以用多个特征来表示更复杂的模型。例如，具有三个特征的模型可以采用以下方程式：

`$y' = w_1x_1+w_2x_1+w_2x_1+w_3x_3+ b$`

### 2.2 训练与损失(经验风险最小化)

:::danger
简单来说，**训练**模型表示通过有标签样本来学习（确定）所有权重和偏差的理想值。在监督式学习中，机器学习算法通过以下方式构建模型：检查多个样本并尝试找出可==最大限度地减少损失的模型==；这一过程称为**经验风险最小化**。
:::


**损失**是对糟糕预测的惩罚。也就是说，损失是一个数值，表示对于单个样本而言模型预测的准确程度。如果模型的预测完全准确，则损失为零，否则损失会较大。训练模型的目标是从所有样本中找到一组平均损失“较小”的权重和偏差。例如，图 3 左侧显示的是损失较大的模型，右侧显示的是损失较小的模型。关于此图，请注意以下几点：

![image.png](http://upload-images.jianshu.io/upload_images/10357485-26165d01c0f5ef4b.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240)

<center>图 3. 左侧模型的损失较大；右侧模型的损失较小。</center>

您可能想知道自己能否创建一个数学函数（损失函数），以有意义的方式汇总各个损失。

:::danger
对于不同的机器学习算法来说，其实就是定义了不同的损失函数
:::

- 平方损失：一种常见的损失函数

接下来我们要看的线性回归模型使用的是一种称为平方损失又称为==L2 损失==的损失函数。单个样本的平方损失如下：

```
  = the square of the difference between the label and the prediction
  = (observation - prediction(x))2
  = (y - y')2
```

![image.png](http://upload-images.jianshu.io/upload_images/10357485-74dd3b0f934a4a11.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240)


## 3 降低损失

:::danger
监督式的机器学习就是在找`最大限度地减少损失的模型`,也就是损失函数最小化
:::

### 3.1 迭代方法


迭代学习可能会让您想到“Hot and Cold”这种寻找隐藏物品（如顶针）的儿童游戏。在我们的游戏中，“隐藏的物品”就是最佳模型。刚开始，您会胡乱猜测（“ `$w_1$` 的值为 0。”），等待系统告诉您损失是多少。然后，您再尝试另一种猜测（“`$w_1$` 的值为 0.5。”），看看损失是多少。哎呀，这次更接近目标了。实际上，如果您以正确方式玩这个游戏，通常会越来越接近目标。这个游戏真正棘手的地方在于尽可能高效地找到最佳模型。


![image.png](http://upload-images.jianshu.io/upload_images/10357485-8daa9e63ce9e7d9b.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240)



![image.png](http://upload-images.jianshu.io/upload_images/10357485-92b8f1abf79331de.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240)

:::info
直到总体损失不再变化或至少变化极其缓慢为止。这时候，我们可以说该模型已收敛。
:::


### 3.2 梯度下降法


通过计算整个数据集中`$w_1$`每个可能值的损失函数来找到收敛点这种方法效率太低。我们来研究一种更好的机制，这种机制在机器学习领域非常热门，称为梯度下降法。

> https://developers.google.com/machine-learning/crash-course/reducing-loss/gradient-descent


### 3.3 学习速率

梯度下降法算法用梯度乘以一个称为学习速率（有时也称为步长）的标量，以确定下一个点的位置。例如，如果梯度大小为 2.5，学习速率为 0.01，则梯度下降法算法会选择距离前一个点 0.025 的位置作为下一个点。


==超参数==是编程人员在机器学习算法中用于调整的旋钮。大多数机器学习编程人员会花费相当多的时间来调整学习速率。如果您选择的学习速率过小，就会花费太长的学习时间：


### 3.4 随机梯度下降法

> 在梯度下降法中，主要的经历都在，控制学习速率中，

如果我们可以通过更少的计算量得出正确的平均梯度，会怎么样？通过从我们的数据集中随机选择样本，我们可以通过小得多的数据集估算（尽管过程非常杂乱）出较大的平均值。 随机梯度下降法 (SGD) 将这种想法运用到极致，它每次迭代只使用一个样本（批量大小为 1）。如果进行足够的迭代，SGD 也可以发挥作用，但过程会非常杂乱。“随机”这一术语表示构成各个批量的一个样本都是随机选择的。

小批量随机梯度下降法（小批量 SGD）是介于全批量迭代与 SGD 之间的折衷方案。小批量通常包含 10-1000 个随机选择的样本。小批量 SGD 可以减少 SGD 中的杂乱样本数量，但仍然比全批量更高效。



## 4 tensorflow 环境相关

### 4.1 TensorFlow 工具包的当前层次结构

![image.png](http://upload-images.jianshu.io/upload_images/10357485-2bba9977c0ae67e9.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240)

工具包|说明
---|---
Estimator (tf.estimator)|高级 OOP API。
tf.layers/tf.losses/tf.metrics|用于常见模型组件的库。
TensorFlow|低级 API


TensorFlow 由以下两个组件组成：
:::info
图协议缓冲区

执行（分布式）图的运行时

这两个组件类似于 Java 编译器和 JVM。正如 JVM 会实施在多个硬件平台（CPU 和 GPU）上一样，TensorFlow 也是如此。
:::



## 5 泛化

> 机器学习模型越简单，良好的实证结果就越有可能不仅仅基于样本的特性 ==奥卡姆剃刀==


以下三项基本假设阐明了泛化：

- 我们从分布中随机抽取独立同分布 (i.i.d) 的样本。换言之，样本之间不会互相影响。（另一种解释：i.i.d. 是表示变量随机性的一种方式）。
- 分布是平稳的；即分布在数据集内不会发生变化。
- 我们从同一分布的数据划分中抽取样本。


在实践中，我们有时会违背这些假设。例如：

- 想象有一个选择要展示的广告的模型。如果该模型在某种程度上根据用户以前看过的广告选择广告，则会违背 i.i.d. 假设。
- 想象有一个包含一年零售信息的数据集。用户的购买行为会出现季节性变化，这会违反平稳性。

:::info
> 如果某个模型尝试紧密拟合训练数据，但却不能很好地泛化到新数据，就会发生过拟合。

> 如果不符合监督式机器学习的关键假设，那么我们将失去对新数据进行预测这项能力的重要理论保证。
:::

## 6 训练集和测试集 (Training and Test Sets)：拆分数据

- 测试集满足以下两个条件
    - 规模足够大，可产生具有统计意义的结果。
    - 能代表整个数据集。换言之，挑选的测试集的特征应该与训练集的特征相同。

## 7 验证集


```
graph LR
A[使用训练集训练模型]-->B[使用验证集评估模型]
B[使用验证集评估模型]-->C[根据在验证集上获得的效果调整模型]
C[根据在验证集上获得的效果调整模型]-->A[使用训练集训练模型]
C[根据在验证集上获得的效果调整模型]-->D[选择在验证集上获得最佳效果的模型]
D[选择在验证集上获得最佳效果的模型]-->E[使用测试集确认模型的效果]
```

## 8 表示（特征工程）

> 传统编码关注代码，而机器学习项目中我们关注表示

- 将原始数据映射到特征中

```
特征工程指的是将原始数据转换为特征矢量。进行特征工程预计需要大量时间。
```

![image.png](https://upload-images.jianshu.io/upload_images/10357485-dea4b9a127222f0f.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240)



- 特征工程中的一些方法

```
- 映射数值
机器学习模型根据浮点值进行训练，因此整数和浮点原始数据不需要特殊编码。

- 映射字符串值
首先，为您要表示的所有特征的字符串值定义一个词汇表。
然后，使用该词汇表创建一个独热编码，用于将指定字符串值表示为二元矢量。在该矢量(one-hot)
(该矢量的长度等于词汇表中的元素数) (维数升高)

- 映射分类（枚举）值
类似one-hot方式的编码
```

### 8.1 什么是良好的特征

- 避免很少使用的离散特征值

```
例如房价预测模型中，unique_house_id，就不适合作为特征，因为每个值只使用一次，模型无法从中学习任何规律

良好的特征值应该在数据集中出现大约 5 次以上。
```

- 最好具有清晰明确的含义

```
感性人工理解
```

- 不要将“神奇”的值与实际数据混为一谈

```
排除神奇值

或者将该特征，转换为两个特征
```

- 考虑上游不稳定性

```
特征的定义不应随时间发生变化。
```

### 8.2 清理数据(数据预处理)

- 缩放特征值（特征值归一化）

```
- 帮助梯度下降法更快速地收敛。
- 帮助避免“NaN 陷阱”。在这种陷阱中，模型中的一个数值变成 NaN（例如，当某个值在训练期间超出浮点精确率限制时），并且模型中的所有其他数值最终也会因数学运算而变成 NaN。
- 帮助模型为每个特征确定合适的权重。如果没有进行特征缩放，则模型会对范围较大的特征投入过多精力。
```

- 处理极端离群值

```
1 方法是 取对数（对数缩放可稍稍缓解这种影响，但仍然存在离群值这个大尾巴）
2 或者最大、最小值限定

```

- 分箱

```
对分箱后的数据 进行one-hot
```

- 清查

```
数据集中的很多样本是不可靠的
```

## 9 特征工程-特征组合 feature cross

- 在使用线性模型中，解决非线性问题时，一般的方法是进行特征组合

```
特征组合是指通过将两个或多个输入特征相乘来对特征空间中的非线性规律进行编码的合成特征
```
- 9.1 特征组合的种类

```
[A X B]：将两个特征的值相乘形成的特征组合。
[A x B x C x D x E]：将五个特征的值相乘形成的特征组合。
[A x A]：对单个特征的值求平方形成的特征组合。
```

- 9.2 特征组合 (Feature Crosses)：组合独热矢量

:::info
在实践中，机器学习模型很少会组合连续特征,机器学习模型却经常==组合独热特征矢量==
:::

> 对于大数据机，特征组合是一个有效的策略


## 10 正则化

![image.png](https://upload-images.jianshu.io/upload_images/10357485-0e6912b48f4c52bc.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240)

> 在泛化曲线中，常常看到的情况是这样的，某个模型的训练损失逐渐减少，但验证损失最终增加。换言之，该泛化曲线显示该模型与训练集中的数据过拟合。根据奥卡姆剃刀定律，或许我们可以通过降低复杂模型的复杂度来防止过拟合，这种原则称为==正则化==。

- [x] 也就是说，模型的目标不是最小化损失`$minimise(Lose(Data|Model))$`,而是最小化损失和复杂度。这称为==结构风险最小化==，`$minimise(Lose(Data|Model))+complexity(model)$`

> 我们的训练优化算法是一个由两项内容组成的函数：一个是==损失项==，用于衡量模型与数据的拟合度，另一个是==正则化项==，用于衡量模型复杂度

### 10.1 两种衡量模型复杂度的方法

- L2 正则化 该公式将正则化项定义为所有特征权重的平方和

`$L_2\text{ regularization term} = ||w||_2^2 = w_1^2 + w_2^2 + ... + w_n^2$`


### 10.2 引入正则化率

模型开发者通过以下方式来调整正则化项的整体影响：用正则化项的值乘以名为 lambda（又称为正则化率）的标量。也就是说，模型开发者会执行以下运算

`$\text{minimize(Loss(Data|Model)} + \lambda \text{ complexity(Model))}$`

执行 L2 正则化对模型具有以下影响:

- 使权重值接近于 0（但并非正好为 0）
- 使权重的平均值接近于 0，且呈正态（钟形曲线或高斯曲线）分布。

增加 lambda 值将增强正则化效果:

![image.png](https://upload-images.jianshu.io/upload_images/10357485-c9a2697940762a29.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240)

降低 lambda 的值往往会得出比较平缓的直方图:

![image.png](https://upload-images.jianshu.io/upload_images/10357485-b29765cf9834f327.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240)


:::info
在选择 lambda 值时，目标是在简单化和训练数据拟合之间达到适当的平衡：

> 如果您的 lambda 值过高，则模型会非常简单，但是您将面临数据欠拟合的风险。您的模型将无法从训练数据中获得足够的信息来做出有用的预测。

> 如果您的 lambda 值过低，则模型会比较复杂，并且您将面临数据过拟合的风险。您的模型将因获得过多训练数据特点方面的信息而无法泛化到新数据。
:::


## 11 逻辑回归(Logistic Regression)：计算概率

许多问题需要将概率估算值作为输出。逻辑回归是一种极其高效的概率计算机制。

- 线性回归的损失函数是平方损失，逻辑回归损失函数称之为==对数损失函数==

`$Log Loss = \sum_{(x,y)\in D} -ylog(y') - (1 - y)log(1 - y')$`


`$y' = \frac{1}{1 + e^{-(z)}}$`

如上的 S 型函数 将模型预测值映射到0-1空间

注意 `z 也称为对数几率`，因为 S 型函数的反函数表明,z 可定义为标签“1”（例如“狗叫”）的概率除以标签“0”（例如“狗不叫”）的概率得出的值的对数

`$z = log(\frac{y}{1-y})$`


- (xy)ϵD 是包含很多有标签样本 (x,y) 的数据集。
- “y”是有标签样本中的标签。由于这是逻辑回归，因此“y”的每个值必须是 0 或 1。
- “y'”是对于特征集“x”的预测值（介于 0 和 1 之间）。

- 对数损失函数的方程式与 Shannon 信息论中的熵测量密切相关。它也是似然函数的负对数（假设“y”属于伯努利分布）。实际上，最大限度地降低损失函数的值会生成最大的似然估计值。


## 12 分类

### 12.1 分类阈值

> 在逻辑回归中，可以“原样”使用返回的概率信息，也可以将返回的概率转换成二元值（例如，这封电子邮件是垃圾邮件）。 区别是使用了==分类阈值==

### 12.2 分类中真与假以及正类别与负类别(分类问题评估标准)


 混淆矩阵 |  混淆矩阵
---|---
真正例 (TP)：<br>真实情况：受到狼的威胁。<br>牧童说：“狼来了。”<br>结果：牧童是个英雄。 | 假正例 (FP)：<br>真实情况：没受到狼的威胁。<br>牧童说：“狼来了。” <br>结果：村民们因牧童吵醒他们而感到非常生气。<br>
假负例 (FN)：<br>真实情况：受到狼的威胁。<br>牧童说：“没有狼”。<br>结果：狼吃掉了所有的羊。 | 真负例 (TN)：<br>真实情况：没受到狼的威胁。<br>牧童说：“没有狼”。<br>结果：大家都没事。

:::danger

- 准确率 : 模型预测正确的结果所占的比例

`$\text{Accuracy} = \frac{TP+TN}{TP+TN+FP+FN}$`

> 注意：当您使用==分类不平衡的数据集==（比如正类别标签和负类别标签的数量之间存在明显差异）时，单单准确率一项并不能反映全面情况。

- 精确率（强调没有假正例的重要性）

`$\text{Precision} = \frac{TP}{TP+FP}$`

- 召回率（强调没有假负例的重要性）

`$\text{召回率} = \frac{TP}{TP+FN}$`

> 要全面评估模型的有效性，必须同时检查精确率和召回率。遗憾的是，精确率和召回率往往是此消彼长的情况。也就是说，提高精确率通常会降低召回率值，反之亦然。
:::

### 12.3 ROC 和曲线下面积（另一种评估标准）

> ROC 曲线（接收者操作特征曲线）是一种显示分类模型在所有分类阈值下的效果的图表

> https://www.jianshu.com/p/c61ae11cc5f6


```
(1) 真阳性(True Positive，TP)：检测有结节，且实际有结节；正确肯定的匹配数目；
(2) 假阳性(False Positive，FP)：检测有结节，但实际无结节；误报，给出的匹配是不正确的；
(3) 真阴性(True Negative，TN)：检测无结节，且实际无结节；正确拒绝的非匹配数目；
(4) 假阴性(False Negative，FN)：检测无结节，但实际有结节；漏报，没有正确找到的匹配的数目。
```

![image](https://upload-images.jianshu.io/upload_images/145616-0a7a7fd1ff77dcd9.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/700)

